% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/1.1.f.data.prep.R
\name{split_poly}
\alias{split_poly}
\title{Split a species occ polygon (whenever distribution seems disjoint) into K polygons and save in a single .shp}
\usage{
split_poly(occ.spdf, k = NULL, nm.col.dt = NULL, c.m = "NB", r = 2,
  q = 0.3, distance = "euclidean", min.nc = 1, max.nc = 20,
  method = "centroid", index = "trcovw", alphaBeale = 0.1,
  convex = TRUE, alpha = 10, sp.nm = "species", save = T,
  crs.set = "+proj=longlat +datum=WGS84")
}
\arguments{
\item{occ.spdf}{An object of class SpatialPoints or SpatialPointsDataFrame (e.g. species occurence coordinates)}

\item{k}{number of polygons to create based on coordinates}

\item{nm.col.dt}{"character". Name of a numeric column to use as grouping variable in addition to coordinates.}

\item{c.m}{clustering method to find the best number of clusters (k). Currently E (Elbow) or (Affinity Propagation).}

\item{r}{exponent (see details below)}

\item{q}{if \code{p=NA}, exemplar preferences are initialized
    according to the distribution of non-Inf values in \code{s}.
    If \code{q=NA}, exemplar preferences are set to the median
    of non-Inf values in \code{s}. If \code{q} is a value
    between 0 and 1, the sample quantile with threshold
    \code{q} is used, whereas \code{q=0.5} again results in
    the median.}

\item{distance}{the distance measure to be used to compute the dissimilarity matrix. This must be one of: "euclidean", "maximum", "manhattan", "canberra", "binary", "minkowski" or "NULL". By default, distance="euclidean". 
If the distance is "NULL", the dissimilarity matrix (diss) should be given by the user. If distance is not "NULL", the dissimilarity matrix should be "NULL".}

\item{min.nc}{minimal number of clusters, between 1  and (number of objects - 1)}

\item{max.nc}{maximal number of clusters, between 2 and (number of objects - 1), greater or equal to min.nc. By default, max.nc=15.}

\item{method}{type of distance measure to be used; for \code{negDistMat},
    \code{expSimMat} and \code{linSimMat}, this argument is analogous to the
    \code{method} argument of \code{\link[stats:dist]{dist}}.
    For \code{corSimMat}, this argument is analogous to the \code{method}
    argument of \code{\link[stats:cor]{cor}}.}

\item{index}{the index to be calculated. This should be one of : "kl", "ch", "hartigan", "ccc", "scott", "marriot", "trcovw", "tracew", "friedman",  "rubin", "cindex",  "db", "silhouette", "duda", "pseudot2", "beale",  "ratkowsky", "ball", "ptbiserial", "gap", "frey", "mcclain", "gamma", "gplus", "tau", "dunn", "hubert", "sdindex", "dindex", "sdbw", "all" (all indices except GAP, Gamma, Gplus and Tau), "alllong" (all indices with Gap, Gamma, Gplus and Tau included).}

\item{alphaBeale}{significance value for Beale's index.}

\item{convex}{Logical. Convex (T) or concave (F) polygon}

\item{alpha}{Value of \eqn{\alpha}.}

\item{sp.nm}{Species name, used on saving shapefile}

\item{save}{Should save polygons on disk?}

\item{crs.set}{set the coordinate reference system (CRS) of the polygons}
}
\value{
spatial polygons built using coordinates
}
\description{
Cluster points and create several small polygons. Implemented methods are 'Hierarchical Clustering' (when 'k'
number of clusters is defined 'k > 0'), 'Elbow' (c.m = "E"), 'Affinity Propagation' (c.m = AP), and several methods
implemented in function NbClust of NbClust package (c.m = "NB"). To use NbClust package, check arguments 'distance',
'min.nc', 'max.nc', 'method', and 'index' in ?NbClust::NbClust.
}
\examples{
\dontrun{
Bvarieg.occ <- read.table(paste(system.file(package="dismo"),
 "/ex/bradypus.csv", sep=""), header=TRUE, sep=",")
colnames(Bvarieg.occ) <- c("SPEC", "LONG", "LAT")
spp.occ.list <- list(Bvarieg = Bvarieg.occ)
occ.polys <- set_calibarea_b(spp.occ.list)
occ.polys$Bvarieg <- split_poly(occ.spdf = spp.occ.list$Bvarieg, k=5)
}
}
\seealso{
\code{\link{set_calibarea}}, \code{\link{set_calibarea_b}}, \code{\link[NbClust]{NbClust}}
}
\keyword{internal}
